{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"reference/","title":"\ud83d\udd27 Core Services","text":"<p>[[developmentServices]] [[hosting]] [[venv]] [[powerLevel10]] [[environment]] [[nas]] [[macvlan]] [[hetznerCert]] [[brew]] [[management]] [[sharedConfig]] [[posts/code/index|index]] [[index]] [[tags]]</p>","tags":["Networking","DNS","Proxy"]},{"location":"tags/","title":"Tags","text":""},{"location":"tags/#tag:authentication","title":"Authentication","text":"<ul> <li>            \ud83d\udee1\ufe0f Authentik          </li> </ul>"},{"location":"tags/#tag:certificate","title":"Certificate","text":"<ul> <li>            \ud83d\udd10 Hetzner Certificate          </li> </ul>"},{"location":"tags/#tag:code","title":"Code","text":"<ul> <li>            \ud83c\udfd7 Code Documentation          </li> </ul>"},{"location":"tags/#tag:control","title":"Control","text":"<ul> <li>            \ud83d\udcbb Development Services          </li> </ul>"},{"location":"tags/#tag:dns","title":"DNS","text":"<ul> <li>            \ud83d\udd27 Core Services          </li> <li>            \ud83d\udd27 Core Services          </li> </ul>"},{"location":"tags/#tag:docker","title":"Docker","text":"<ul> <li>            \ud83c\udf10 Docker Macvlan          </li> </ul>"},{"location":"tags/#tag:dotenv","title":"Dotenv","text":"<ul> <li>            \ud83d\udcc4 Dotenv          </li> </ul>"},{"location":"tags/#tag:entware","title":"Entware","text":"<ul> <li>            \ud83d\uddc4\ufe0f NAS Script          </li> </ul>"},{"location":"tags/#tag:global","title":"Global","text":"<ul> <li>            \u2699\ufe0f Shared Config          </li> <li>            \ud83c\udf3f Environment          </li> </ul>"},{"location":"tags/#tag:hetzner","title":"Hetzner","text":"<ul> <li>            \ud83d\udd10 Hetzner Certificate          </li> </ul>"},{"location":"tags/#tag:homebrew","title":"Homebrew","text":"<ul> <li>            \ud83c\udfd7 Homebrew Installation          </li> </ul>"},{"location":"tags/#tag:ide","title":"IDE","text":"<ul> <li>            \ud83d\udcbb Development Services          </li> </ul>"},{"location":"tags/#tag:infrastructure","title":"Infrastructure","text":"<ul> <li>            \u2757 Container Management          </li> </ul>"},{"location":"tags/#tag:linux","title":"Linux","text":"<ul> <li>            \ud83c\udfd7 Homebrew Installation          </li> </ul>"},{"location":"tags/#tag:management","title":"Management","text":"<ul> <li>            \u2757 Container Management          </li> </ul>"},{"location":"tags/#tag:mkdocs","title":"MkDocs","text":"<ul> <li>            \ud83d\udc0d Venv Script          </li> </ul>"},{"location":"tags/#tag:nas","title":"NAS","text":"<ul> <li>            \ud83d\uddc4\ufe0f NAS Script          </li> </ul>"},{"location":"tags/#tag:networking","title":"Networking","text":"<ul> <li>            \ud83c\udf10 Docker Macvlan          </li> <li>            \ud83d\udd27 Core Services          </li> <li>            \ud83d\udd27 Core Services          </li> </ul>"},{"location":"tags/#tag:note","title":"Note","text":"<ul> <li>            \ud83d\udcbb Development Services          </li> </ul>"},{"location":"tags/#tag:powerlevel10k","title":"Powerlevel10k","text":"<ul> <li>            \ud83c\udfa8 Powerlevel10k Script          </li> </ul>"},{"location":"tags/#tag:proxy","title":"Proxy","text":"<ul> <li>            \ud83d\udd27 Core Services          </li> <li>            \ud83d\udd27 Core Services          </li> </ul>"},{"location":"tags/#tag:python","title":"Python","text":"<ul> <li>            \ud83d\udc0d Venv Script          </li> </ul>"},{"location":"tags/#tag:ssl","title":"SSL","text":"<ul> <li>            \ud83d\udd10 Hetzner Certificate          </li> </ul>"},{"location":"tags/#tag:sso","title":"SSO","text":"<ul> <li>            \ud83d\udee1\ufe0f Authentik          </li> </ul>"},{"location":"tags/#tag:script","title":"Script","text":"<ul> <li>            \ud83c\udf10 Docker Macvlan          </li> <li>            \ud83c\udfa8 Powerlevel10k Script          </li> <li>            \ud83c\udfd7 Homebrew Installation          </li> <li>            \ud83d\udc0d Venv Script          </li> <li>            \ud83d\udd10 Hetzner Certificate          </li> <li>            \ud83d\uddc4\ufe0f NAS Script          </li> </ul>"},{"location":"tags/#tag:synology","title":"Synology","text":"<ul> <li>            \ud83d\uddc4\ufe0f NAS Script          </li> </ul>"},{"location":"tags/#tag:taking","title":"Taking","text":"<ul> <li>            \ud83d\udcbb Development Services          </li> </ul>"},{"location":"tags/#tag:theme","title":"Theme","text":"<ul> <li>            \ud83c\udfa8 Powerlevel10k Script          </li> </ul>"},{"location":"tags/#tag:version","title":"Version","text":"<ul> <li>            \ud83d\udcbb Development Services          </li> </ul>"},{"location":"tags/#tag:virtualenv","title":"Virtualenv","text":"<ul> <li>            \ud83d\udc0d Venv Script          </li> </ul>"},{"location":"tags/#tag:zsh","title":"Zsh","text":"<ul> <li>            \ud83c\udfa8 Powerlevel10k Script          </li> </ul>"},{"location":"tags/#tag:macos","title":"macOS","text":"<ul> <li>            \ud83c\udfd7 Homebrew Installation          </li> </ul>"},{"location":"authentik/","title":"\ud83d\udee1\ufe0f Authentik Identity Provider","text":"<p>Production-ready identity and access management solution with SSO, user directories, and multi-factor authentication.</p>","tags":["Authentication","SSO"]},{"location":"authentik/#service-configuration","title":"\ud83d\udee0\ufe0f Service Configuration","text":"<ul> <li>This setup uses the shared Docker Compose anchors for:</li> <li>Logging (<code>default-logging</code>)</li> <li>Labels (<code>default-labels</code>)</li> <li>Resource limits (<code>resource-limits</code>)</li> </ul>","tags":["Authentication","SSO"]},{"location":"authentik/#core-services","title":"Core Services","text":"authentik.yml<pre><code>---\nx-logging: &amp;default-logging\n  driver: loki\n  options: &amp;default-logging-options\n    loki-url: https://loki.${SYNOLOGY_BASIC_URL}/loki/api/v1/push\n    loki-retries: 5\n    loki-batch-size: 400\n    loki-batch-wait: 2s\n    loki-timeout: 10s\n    loki-max-backoff: 5s\n    loki-min-backoff: 1s\n    loki-tenant-id: default\n\nx-labels: &amp;default-labels\n  com.centurylinklabs.watchtower.enable: true\n  recreat.container: true\n  container.label.group: proxy\n\nx-limits: &amp;resource-limits\n  mem_limit: \"256m\"\n  mem_reservation: \"64m\"\n  cpu_shares: \"512\"\n  restart: always\n  networks:\n    dockerization:\n\nservices:\n  postgresql:\n    container_name: authentik-postgresql\n    hostname: authentik-postgresql\n    image: docker.io/library/postgres:16-alpine\n    &lt;&lt;: *resource-limits\n    logging:\n      &lt;&lt;: *default-logging\n      options:\n        &lt;&lt;: *default-logging-options\n        loki-external-labels: job=authentik-postgresql\n    healthcheck:\n      test:\n        - CMD-SHELL\n        - pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}\n      start_period: 20s\n      interval: 30s\n      retries: 5\n      timeout: 5s\n    volumes:\n      - type: bind\n        source: ${MOUNT_PATH_DOCKER_ROOT:?path required}/authentik/database\n        target: /var/lib/postgresql/data\n      - type: bind\n        source: /etc/localtime\n        target: /etc/localtime\n        read_only: true\n    environment:\n      POSTGRES_PASSWORD: ${PG_PASS:?database password required} # (1)!\n      POSTGRES_USER: ${PG_USER:-authentik} # (2)!\n      POSTGRES_DB: ${PG_DB:-authentik} # (3)!\n      UID: ${UID_NAS_ADMIN:-1026} # (4)!\n      GID: ${GID_NAS_ADMIN:-100} # (5)!\n    labels:\n      &lt;&lt;: *default-labels\n      monitoring: authentik-postgresql\n\n  redis:\n    container_name: authentik-redis\n    hostname: authentik-redis\n    image: docker.io/library/redis:alpine\n    command: --save 60 1 --loglevel warning\n    &lt;&lt;: *resource-limits\n    logging:\n      &lt;&lt;: *default-logging\n      options:\n        &lt;&lt;: *default-logging-options\n        loki-external-labels: job=authentik-redis\n    healthcheck:\n      test:\n        - CMD-SHELL\n        - redis-cli ping | grep PONG\n      start_period: 20s\n      interval: 30s\n      retries: 5\n      timeout: 3s\n    volumes:\n      - type: bind\n        source: ${MOUNT_PATH_DOCKER_ROOT}/authentik/redis\n        target: /data\n      - type: bind\n        source: /etc/localtime\n        target: /etc/localtime\n        read_only: true\n    environment:\n      UID: ${UID_NAS_ADMIN:-1026} # (6)!\n      GID: ${GID_NAS_ADMIN:-100} # (7)!\n    labels:\n      &lt;&lt;: *default-labels\n      monitoring: authentik-redis\n\n  authentik:\n    container_name: authentik\n    hostname: authentik\n    image: ${AUTHENTIK_IMAGE:-ghcr.io/goauthentik/server}:${AUTHENTIK_TAG:-2025.2.1}\n    command: server\n    &lt;&lt;: *resource-limits\n    logging:\n      &lt;&lt;: *default-logging\n      options:\n        &lt;&lt;: *default-logging-options\n        loki-external-labels: job=authentik\n    environment:\n      AUTHENTIK_REDIS__HOST: redis # (8)!\n      AUTHENTIK_POSTGRESQL__HOST: postgresql # (9)!\n      AUTHENTIK_POSTGRESQL__USER: ${PG_USER:-authentik} # (10)!\n      AUTHENTIK_POSTGRESQL__NAME: ${PG_DB:-authentik} # (11)!\n      AUTHENTIK_POSTGRESQL__PASSWORD: ${PG_PASS} # (12)!\n      AUTHENTIK_BOOTSTRAP_EMAIL: ${EMAIL} # (13)!\n      AUTHENTIK_BOOTSTRAP_PASSWORD: ${AUTHENTIK_BOOTSTRAP_PASSWORD} # (14)!\n      AUTHENTIK_SECRET_KEY: ${AUTHENTIK_SECRET_KEY} # (15)!\n      UID: ${UID_NAS_ADMIN:-1026} # (16)!\n      GID: ${GID_NAS_ADMIN:-100} # (17)!\n    volumes:\n      - type: bind\n        source: /etc/localtime\n        target: /etc/localtime\n        read_only: true\n      - type: bind\n        source: ${MOUNT_PATH_DOCKER_ROOT}/authentik/media\n        target: /media\n      - type: bind\n        source: ${MOUNT_PATH_DOCKER_ROOT}/authentik/templates\n        target: /templates\n    ports:\n      - ${COMPOSE_PORT_HTTP:-9001}:9000\n      - ${COMPOSE_PORT_HTTPS:-9443}:9443\n    depends_on:\n      postgresql:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    labels:\n      &lt;&lt;: *default-labels\n      monitoring: authentik\n\n  worker:\n    container_name: authentik-worker\n    hostname: authentik-worker\n    image: ${AUTHENTIK_IMAGE:-ghcr.io/goauthentik/server}:${AUTHENTIK_TAG:-2025.2.1}\n    command: worker\n    &lt;&lt;: *resource-limits\n    logging:\n      &lt;&lt;: *default-logging\n      options:\n        &lt;&lt;: *default-logging-options\n        loki-external-labels: job=authentik-worker\n    environment:\n      AUTHENTIK_REDIS__HOST: redis # (18)!\n      AUTHENTIK_POSTGRESQL__HOST: postgresql # (19)!\n      AUTHENTIK_POSTGRESQL__USER: ${PG_USER:-authentik} # (20)!\n      AUTHENTIK_POSTGRESQL__NAME: ${PG_DB:-authentik} # (21)!\n      AUTHENTIK_POSTGRESQL__PASSWORD: ${PG_PASS} # (22)!\n      AUTHENTIK_BOOTSTRAP_EMAIL: ${EMAIL} # (23)!\n      AUTHENTIK_BOOTSTRAP_PASSWORD: ${AUTHENTIK_BOOTSTRAP_PASSWORD} # (24)!\n      AUTHENTIK_SECRET_KEY: ${AUTHENTIK_SECRET_KEY} # (25)!\n      UID: ${UID_NAS_ADMIN:-1026} # (26)!\n      GID: ${GID_NAS_ADMIN:-100} # (27)!\n    user: root\n    volumes:\n      - type: bind\n        source: /var/run/docker.sock\n        target: /var/run/docker.sock\n        read_only: true\n      - type: bind\n        source: /etc/localtime\n        target: /etc/localtime\n        read_only: true\n      - type: bind\n        source: ${MOUNT_PATH_DOCKER_ROOT}/authentik/media\n        target: /media\n      - type: bind\n        source: ${MOUNT_PATH_DOCKER_ROOT}/authentik/certs\n        target: /certs\n      - type: bind\n        source: ${MOUNT_PATH_DOCKER_ROOT}/authentik/templates\n        target: /templates\n    depends_on:\n      postgresql:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    labels:\n      &lt;&lt;: *default-labels\n      monitoring: authentik\n\nnetworks:\n  dockerization:\n    external: true\n</code></pre> <ol> <li>\u2192 Required database password (must be set in <code>.env</code>)</li> <li>\u2192 Database username (default: <code>authentik</code>)</li> <li>\u2192 Database name (default: <code>authentik</code>)</li> <li>\u2192 Optional user ID for volume permissions (default: 1026)</li> <li>\u2192 Optional group ID for volume permissions (default: 100)</li> <li>\u2192 Optional user ID for volume permissions (default: 1026)</li> <li>Optional group ID for volume permissions (default: 100)</li> <li>\u2192 Redis hostname (using Docker service name)</li> <li>\u2192 PostgreSQL hostname (using Docker service name)</li> <li>\u2192 PostgreSQL username (matches <code>POSTGRES_USER</code>)</li> <li>\u2192 Database name (matches <code>POSTGRES_DB</code>)</li> <li>\u2192 Must match <code>POSTGRES_PASSWORD</code></li> <li>\u2192 Initial admin email (must be set in <code>.env</code>)</li> <li>\u2192 Initial admin password (must be set in <code>.env</code>)</li> <li>\u2192 Encryption key (must be set in <code>.env</code>)</li> <li>\u2192 User ID for volume permissions (default: 1026)</li> <li>\u2192 Group ID for volume permissions (default: 100)</li> <li>\u2192 Redis hostname (using Docker service name)</li> <li>\u2192 PostgreSQL hostname (using Docker service name)</li> <li>\u2192 PostgreSQL username (matches <code>POSTGRES_USER</code>)</li> <li>\u2192 Database name (matches <code>POSTGRES_DB</code>)</li> <li>\u2192 Must match <code>POSTGRES_PASSWORD</code></li> <li>\u2192 Initial admin email (must be set in <code>.env</code>)</li> <li>\u2192 Initial admin password (must be set in <code>.env</code>)</li> <li>\u2192 Encryption key (must be set in <code>.env</code>)</li> <li>\u2192 User ID for volume permissions (default: 1026)</li> <li>\u2192 Group ID for volume permissions (default: 100)</li> </ol>","tags":["Authentication","SSO"]},{"location":"authentik/#required-environment-variables","title":"\ud83d\udd10 Required Environment Variables","text":"<p>Refer to <code>Environment Variables</code> documentation for:</p> Variable Description Required <code>PG_PASS</code> PostgreSQL password \u2705 <code>AUTHENTIK_BOOTSTRAP_PASSWORD</code> Initial admin password \u2705 <code>AUTHENTIK_SECRET_KEY</code> Encryption key \u2705 <code>MOUNT_PATH_DOCKER_ROOT</code> Storage path \u2705 <code>UID_NAS_ADMIN</code> User ID for volume permissions \u26a0\ufe0f Recommended <code>GID_NAS_ADMIN</code> Group ID for volume permissions \u26a0\ufe0f Recommended <p>Security Notice</p> <ul> <li>Be stored in <code>.env</code> files</li> <li>Have restricted permissions (<code>chmod 600</code>)</li> <li>Never be committed to version control</li> <li>Be rotated periodically</li> </ul>","tags":["Authentication","SSO"]},{"location":"authentik/#deployment","title":"\ud83d\ude80 Deployment","text":"<ol> <li>Create <code>.env</code> file with required variables</li> <li>Initialize volumes <pre><code>mkdir -p ${MOUNT_PATH_DOCKER_ROOT}/authentik/{database,redis,media,certs,templates}\nchown -R ${UID_NAS_ADMIN:-1026}:${GID_NAS_ADMIN:-100} ${MOUNT_PATH_DOCKER_ROOT}/authentik\n</code></pre></li> <li>Start services <pre><code>docker-compose -f authentik.yml up -d\n</code></pre></li> <li>Access web UI at <code>https://yourdomain.com:9443</code></li> </ol>","tags":["Authentication","SSO"]},{"location":"authentik/#maintenance","title":"\ud83d\udd04 MaintenanceShare on Social Media","text":"<ul> <li> <p>Backups</p> <ul> <li>Regularly backup the PostgreSQL volume</li> </ul> </li> <li> <p>Updates</p> </li> </ul> <p><pre><code>docker-compose -f authentik.yml pull\ndocker-compose -f authentik.yml up -d\n</code></pre> - Logs <pre><code>docker worker logs -f\n</code></pre></p>              Share on X                       Share on Facebook","tags":["Authentication","SSO"]},{"location":"development/","title":"\ud83d\udcbb Development Environment Stack","text":"<p>Integrated development environment with code editor, version control, and knowledge management.</p>","tags":["IDE","Version","Control","Note","Taking"]},{"location":"development/#service-configuration","title":"\ud83d\udee0\ufe0f Service Configuration","text":"<ul> <li>This setup uses #the shared Docker Compose anchors for:</li> <li>Logging (<code>default-logging</code>)</li> <li>Labels (<code>default-labels</code>)</li> <li>Resource limits (<code>resource-limits</code>)</li> </ul>","tags":["IDE","Version","Control","Note","Taking"]},{"location":"development/#development-services","title":"Development Services","text":"venv.sh<pre><code>---\nx-logging: &amp;default-logging\n  driver: loki\n  options: &amp;default-logging-options\n    loki-url: https://loki.${SYNOLOGY_BASIC_URL}/loki/api/v1/push\n    loki-retries: 5\n    loki-batch-size: 400\n    loki-batch-wait: 2s\n    loki-timeout: 10s\n    loki-max-backoff: 5s\n    loki-min-backoff: 1s\n    loki-tenant-id: default\n\nx-labels: &amp;default-labels\n  com.centurylinklabs.watchtower.enable: true\n  recreat.container: true\n  container.label.group: development\n\nx-limits: &amp;resource-limits\n  mem_limit: \"256m\"\n  mem_reservation: \"64m\"\n  cpu_shares: \"512\"\n  restart: always\n  networks:\n    dockerization:\n\nservices:\n  obsidian:\n    container_name: obsidian\n    hostname: obsidian\n    image: ghcr.io/linuxserver/obsidian:latest\n    shm_size: \"5gb\"\n    &lt;&lt;: *resource-limits\n    security_opt:\n      - no-new-privileges:false\n      - seccomp:unconfined\n    healthcheck:\n      test: timeout 10s bash -c ':&gt; /dev/tcp/127.0.0.1/3000' || exit 1\n      interval: 10s\n      timeout: 5s\n      retries: 3\n      start_period: 90s\n    logging:\n      &lt;&lt;: *default-logging\n      options:\n        &lt;&lt;: *default-logging-options\n        loki-external-labels: job=obsidian\n    ports:\n      - '${OBSIDIAN_PORT:-3421}:3000'\n    volumes:\n      - type: bind\n        source: /etc/localtime\n        target: /etc/localtime\n        read_only: true\n      - type: bind\n        source: ${MOUNT_PATH_DOCKER_ROOT}/obsidian\n        target: /config\n    environment:\n      CUSTOM_USER: ${EMAIL} # (1)!\n      PASSWORD: ${OBSIDIAN_PASSWORD} # (2)!\n      UID: ${UID_NAS_ADMIN:-1026} # (3)!\n      GID: ${GID_NAS_ADMIN:-100} # (4)!\n    labels:\n      &lt;&lt;: *default-labels\n      monitoring: obsidian\n  gitlab:\n    container_name: gitlab\n    hostname: \"gitlab.${SYNOLOGY_BASIC_URL:?Synology URL required}\"\n    &lt;&lt;: *resource-limits\n    logging:\n      &lt;&lt;: *default-logging\n      options:\n        &lt;&lt;: *default-logging-options\n        loki-external-labels: job=gitlab\n    environment:\n      UID: ${UID_NAS_ADMIN:-1026} # (5)!\n      GID: ${GID_NAS_ADMIN:-100} # (6)!\n      GITLAB_OMNIBUS_CONFIG: | # (7)!\n        external_url 'https://gitlab.${SYNOLOGY_BASIC_URL}'\n        gitlab_rails['gitlab_shell_ssh_port'] = 22\n        gitlab_rails['gitlab_shell_git_timeout'] = 800\n        gitlab_rails['gitlab_email_enabled'] = true\n        gitlab_rails['gitlab_email_from'] = '${MAIL_RECEIVER}'\n        gitlab_rails['gitlab_email_display_name'] = 'Synology Gitlab'\n        gitlab_rails['gitlab_email_reply_to'] = '${MAIL_RECEIVER}'\n        gitlab_rails['smtp_enable'] = true\n        gitlab_rails['smtp_address'] = '${SMTP_HOST:-smtp.mail.me.com}'\n        gitlab_rails['smtp_port'] = '${SMTP_PORT:-587}'\n        gitlab_rails['smtp_user_name'] = '${EMAIL}'\n        gitlab_rails['smtp_password'] = '${SMTP_PASSWORD}'\n        gitlab_rails['smtp_domain'] = 'icloud.com'\n        gitlab_rails['smtp_authentication'] = 'login'\n        gitlab_rails['smtp_enable_starttls_auto'] = true\n        gitlab_rails['gitlab_root_email'] = '${EMAIL}'\n        gitlab_rails['lfs_enabled'] = true\n        nginx['proxy_connect_timeout'] = 300\n        nginx['proxy_read_timeout'] = 3600\n        registry['enable'] = true\n        registry_external_url 'https://gitlab.${SYNOLOGY_BASIC_URL}:${GITLAB_REGISTRY:-5005}'\n    ports:\n      - \"${GITLAB_HTTPS:-5100}:443\" # (8)!\n      - \"${GITLAB_REGISTRY:-5101}:5005\" # (9)!\n      - \"${GITLAB_SSH:-5102}:22\" # (10)!\n    volumes:\n      - type: bind\n        source: ${MOUNT_PATH_DOCKER_ROOT}/gitlab/config\n        target: /etc/gitlab\n      - type: bind\n        source: ${MOUNT_PATH_DOCKER_ROOT}/logs/gitlab\n        target: /var/log/gitlab\n      - type: bind\n        source: ${MOUNT_PATH_DOCKER_ROOT}/gitlab/data\n        target: /var/opt/gitlab\n      - type: bind\n        source: /etc/localtime\n        target: /etc/localtime\n        read_only: true\n    labels:\n      &lt;&lt;: *default-labels\n      monitoring: gitlab\n\n  gitlab-runner:\n    container_name: gitlab-runner\n    hostname: gitlab-runner\n    &lt;&lt;: *resource-limits\n    logging:\n      &lt;&lt;: *default-logging\n      options:\n        &lt;&lt;: *default-logging-options\n        loki-external-labels: job=gitlab-runner\n    environment:\n      UID: ${UID_NAS_ADMIN:-1026} # (11)!\n      GID: ${GID_NAS_ADMIN:-100} # (12)!\n    volumes:\n      - type: bind\n        source: /etc/localtime\n        target: /etc/localtime\n        read_only: true\n      - type: bind\n        source: /var/run/docker.sock\n        target: /var/run/docker.sock\n        read_only: true\n      - type: bind\n        source: ${MOUNT_PATH_DOCKER_ROOT}/gitlab/runner\n        target: /etc/gitlab-runner\n    labels:\n      &lt;&lt;: *default-labels\n      monitoring: gitlab-runner\n\nnetworks:\n  dockerization:\n    external: true\n</code></pre> <ol> <li>\u2192 Creates Python virtual environment in <code>venv</code> folder</li> <li>\u2192 Activates the environment using Windows path</li> <li>\u2192 Installs all dependencies from requirements file</li> <li>\u2192 Builds MkDocs documentation with detailed output</li> <li>User ID for volume permissions (default: 1026)</li> <li>Group ID for volume permissions (default: 100)</li> <li>Base URL for GitLab instance    SSH port for Git operations    Git operation timeout (seconds)    Enable email notifications    Sender email address    Email display name    Reply-to email address    Enable SMTP service    SMTP server address    SMTP server port    SMTP username    SMTP password (must be set in <code>.env</code>)    SMTP domain    SMTP auth method    Enable STARTTLS    Admin email address    Enable Git LFS support    Nginx connect timeout    Nginx read timeout    Enable container registry    Registry external URL</li> <li>Web UI port (default: 5100)</li> <li>Container registry port (default: 5101)</li> <li>Git SSH port (default: 5102)</li> <li>User ID for volume permissions (default: 1026)</li> <li>Group ID for volume permissions (default: 100)</li> </ol>","tags":["IDE","Version","Control","Note","Taking"]},{"location":"development/#required-environment-variables","title":"\ud83d\udd10 Required Environment Variables","text":"<p>Refer to Environment Variables documentation for:</p> Variable Description Required <code>SUDO_PASSWORD_VSCODE</code> Code Server password \u2705 <code>OBSIDIAN_PASSWORD</code> Obsidian web interface password \u2705 <code>SMTP_PASSWORD</code> GitLab email password \u2705 <code>MOUNT_PATH_DOCKER_ROOT</code> Storage path \u2705 <code>SYNOLOGY_BASIC_URL</code> Base domain for services \u2705 <code>UID_NAS_ADMIN</code> User ID for volume permissions \u26a0\ufe0f Recommended <code>GID_NAS_ADMIN</code> Group ID for volume permissions \u26a0\ufe0f Recommended <p>Security Notice</p> <p>All sensitive credentials should: - Be stored in <code>.env</code> files - Have restricted permissions (<code>chmod 600</code>) - Never be committed to version control - Be rotated periodically</p>","tags":["IDE","Version","Control","Note","Taking"]},{"location":"development/#deployment","title":"\ud83d\ude80 Deployment","text":"<ol> <li>Create <code>.env</code> file with required variables</li> <li>Initialize volumes <pre><code>mkdir -p ${MOUNT_PATH_DOCKER_ROOT}/{obsidian,gitlab/config,gitlab/data,gitlab/runner,logs/gitlab}\nchown -R ${UID_NAS_ADMIN:-1026}:${GID_NAS_ADMIN:-100} ${MOUNT_PATH_DOCKER_ROOT}\n</code></pre></li> <li>Start services <pre><code>docker-compose up -d\n</code></pre></li> <li>Access services</li> <li>Code Server: <code>https://codeserver.yourdomain.com:${CODE_SERVER:-82}</code></li> <li>Obsidian: <code>https://yourdomain.com:${OBSIDIAN_PORT:-3421}</code></li> <li>GitLab: <code>https://gitlab.yourdomain.com:${GITLAB_HTTPS:-5100}</code></li> </ol>","tags":["IDE","Version","Control","Note","Taking"]},{"location":"development/#maintenance","title":"\ud83d\udd04 MaintenanceShare on Social Media","text":"<ul> <li>Backups<ul> <li>Regularly backup all volume directories</li> </ul> </li> <li>Updates <pre><code>docker-compose pull &amp;&amp; docker-compose up -d --force-recreate\n</code></pre></li> <li>Logs <pre><code>docker-compose logs -f\n</code></pre></li> </ul>              Share on X                       Share on Facebook","tags":["IDE","Version","Control","Note","Taking"]},{"location":"core/","title":"\ud83d\udd27 Core Infrastructure Services","text":"<p>Essential networking stack including DNS resolution, reverse proxy, and cloud tunneling.</p>","tags":["Networking","DNS","Proxy"]},{"location":"core/#service-configuration","title":"\ud83d\udee0\ufe0f Service Configuration","text":"<ul> <li>This setup uses the shared Docker Compose anchors for:</li> <li>Logging (<code>default-logging</code>)</li> <li>Labels (<code>default-labels</code>)</li> <li>Resource limits (<code>resource-limits</code>)</li> </ul>","tags":["Networking","DNS","Proxy"]},{"location":"core/#core-services","title":"Core Services","text":"hosting.yml<pre><code>---\nx-logging: &amp;default-logging\n  driver: loki\n  options: &amp;default-logging-options\n    loki-url: https://loki.${SYNOLOGY_BASIC_URL}/loki/api/v1/push\n    loki-retries: 5\n    loki-batch-size: 400\n    loki-batch-wait: 2s\n    loki-timeout: 10s\n    loki-max-backoff: 5s\n    loki-min-backoff: 1s\n    loki-tenant-id: default\n\nx-labels: &amp;default-labels\n  com.centurylinklabs.watchtower.enable: true\n  recreat.container: true\n  container.label.group: hosting\n\nx-limits: &amp;resource-limits\n  mem_limit: \"256m\"\n  mem_reservation: \"64m\"\n  cpu_shares: \"512\"\n  restart: always\n  networks:\n    dockerization:\n\nservices:\n  cloudflared:\n    container_name: cloudflared\n    hostname: cloudflared\n    image: cloudflare/cloudflared:latest\n    command: tunnel --no-autoupdate run --token ${CLOUDFLARE_TOKEN:?CLOUDFLARE_TOKEN required}\n    healthcheck:\n      test: [\"CMD\", \"cloudflared\", \"--version\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 10s\n    &lt;&lt;: *resource-limits\n    logging:\n      &lt;&lt;: *default-logging\n      options:\n        &lt;&lt;: *default-logging-options\n        loki-external-labels: job=cloudflared\n    environment:\n      UID: ${UID_NAS_ADMIN:-1026} # (1)!\n      GID: ${GID_NAS_ADMIN:-100} # (2)!\n      TUNNEL_METRICS: ${TUNNEL_METRICS:-0.0.0.0:8080} # (3)!\n    volumes:\n      - type: bind\n        source: /etc/localtime\n        target: /etc/localtime\n        read_only: true\n    labels:\n      &lt;&lt;: *default-labels\n      monitoring: cloudflared\n\n  pihole:\n    container_name: pihole\n    hostname: pihole\n    image: pihole/pihole\n    cap_add:\n      - NET_ADMIN\n    security_opt:\n      - no-new-privileges=false\n    deploy:\n      resources:\n        limits:\n          memory: 512MB\n    ulimits:\n      nofile:\n        soft: 65536\n        hard: 65536\n    healthcheck:\n      test: [\"CMD\", \"dig\", \"@127.0.0.1\", \"-p53\", \"pi.hole\"]\n      interval: 1m\n      timeout: 10s\n      retries: 3\n      start_period: 30s\n    logging:\n      &lt;&lt;: *default-logging\n      options:\n        &lt;&lt;: *default-logging-options\n        loki-external-labels: job=pihole\n    environment:\n      UID: ${UID_NAS_ADMIN:-1026} # (4)!\n      GID: ${GID_NAS_ADMIN:-100} # (5)!\n      FTLCONF_LOCAL_IPV4: ${FTLCONF_LOCAL_IPV4:-0.0.0.0} # (6)!\n      FTLCONF_LOCAL_IPV6: ${FTLCONF_LOCAL_IPV6:-::} # (7)!\n      PIHOLE_UID: ${PIHOLE_UID:-1000} # (8)!\n      PIHOLE_GID: ${PIHOLE_GID:-1000} # (9)!\n      DNSMASQ_USER: ${DNSMASQ_USER:-pihole} # (10)!\n      FTLCONF_dns_listeningMode: ${FTLCONF_dns_listeningMode:-all} # (11)!\n      FTLCONF_webserver_port: ${FTLCONF_webserver_port:-80} # (12)!\n      FTLCONF_webserver_api_password: ${PI_HOLE_PASSWORD:?Password is Missing} # (13)!\n      WEBTHEME: ${WEBTHEME:-dark} # (14)!\n      FTLCONF_dns_upstreams: ${FTLCONF_dns_upstreams:-1.1.1.1;1.0.0.1;8.8.8.8;8.8.4.4} # (15)!\n      FTLCONF_QUERY_LOGGING: ${FTLCONF_QUERY_LOGGING:-true} # (16)!\n      FTLCONF_MAXDBDAYS: ${FTLCONF_MAXDBDAYS:-30} # (17)!\n      FTLCONF_PRIVACYLEVEL: ${FTLCONF_PRIVACYLEVEL:-0} # (18)!\n      VIRTUAL_HOST: pihole.${SYNOLOGY_BASIC_URL} # (19)!\n    ports:\n      - target: 53\n        published: 53\n        protocol: tcp\n        mode: host\n      - target: 53\n        published: 53\n        protocol: udp\n        mode: host\n      - target: 80\n        published: 81\n        protocol: tcp\n        mode: host\n    volumes:\n      - type: bind\n        source: ${MOUNT_PATH_DOCKER_ROOT}/config/dnsmasq.d\n        target: /etc/dnsmasq.d\n      - type: bind\n        source: ${MOUNT_PATH_DOCKER_ROOT}/pihole\n        target: /etc/pihole\n      - type: bind\n        source: ${MOUNT_PATH_DOCKER_ROOT}/logs/pihole\n        target: /var/log/pihole\n      - type: bind\n        source: /etc/localtime\n        target: /etc/localtime\n        read_only: true\n    labels:\n      &lt;&lt;: *default-labels\n      monitoring: pihole\n\nnetworks:\n  dockerization:\n    external: true\n</code></pre> <ol> <li>User ID for volume permissions (default: 1026)</li> <li>Group ID for volume permissions (default: 100)</li> <li>Metrics endpoint (default: 0.0.0.0:8080)</li> <li>User ID for permissions (default: 1026)</li> <li>Group ID for permissions (default: 100)</li> <li>IPv4 listening address (default: 0.0.0.0)</li> <li>IPv6 listening address (default: ::)</li> <li>Pi-hole user ID (default: 1000)</li> <li>Pi-hole group ID (default: 1000)</li> <li>DNSMasq user (default: pihole)</li> <li>DNS listening mode (default: all)</li> <li>Web interface port (default: 80)</li> <li>Required admin password</li> <li>Web UI theme (default: dark)</li> <li>Upstream DNS servers</li> <li>Query logging (default: true)</li> <li>Log retention (default: 30 days)</li> <li>Privacy level (default: 0)</li> <li>Virtual host URL</li> </ol>","tags":["Networking","DNS","Proxy"]},{"location":"core/#required-environment-variables","title":"\ud83d\udd10 Required Environment Variables","text":"<p>Refer to Environment Variables documentation for:</p> Variable Description Required <code>CLOUDFLARE_TOKEN</code> Cloudflare Tunnel token \u2705 <code>PI_HOLE_PASSWORD</code> Pi-hole admin password \u2705 <code>INITIAL_ADMIN_PASSWORD</code> NPM admin password \u2705 <code>MOUNT_PATH_DOCKER_ROOT</code> Storage path \u2705 <code>SYNOLOGY_BASIC_URL</code> Base domain for services \u2705 <code>UID_NAS_ADMIN</code> User ID for volume permissions \u26a0\ufe0f Recommended <code>GID_NAS_ADMIN</code> Group ID for volume permissions \u26a0\ufe0f Recommended <p>Security Notice</p> <ul> <li>Be stored in <code>.env</code> files</li> <li>Have restricted permissions (<code>chmod 600</code>)</li> <li>Never be committed to version control</li> <li>Be rotated periodically</li> </ul>","tags":["Networking","DNS","Proxy"]},{"location":"core/#deployment","title":"\ud83d\ude80 Deployment","text":"<ol> <li>Create <code>.env</code> file with required variables</li> <li>Initialize volumes <pre><code>mkdir -p ${MOUNT_PATH_DOCKER_ROOT}/{config/dnsmasq.d,pihole,logs/pihole}\nchown -R ${UID_NAS_ADMIN:-1026}:${GID_NAS_ADMIN:-100} ${MOUNT_PATH_DOCKER_ROOT}\n</code></pre></li> <li>Start services <pre><code>docker-compose -f hosting.yml up -d\n</code></pre></li> </ol>","tags":["Networking","DNS","Proxy"]},{"location":"core/#maintenance","title":"\ud83d\udd04 MaintenanceShare on Social Media","text":"<ul> <li>Backups<ul> <li>Regularly backup volume directories</li> </ul> </li> <li>Updates <pre><code>docker-compose -f hosting.yml pull\ndocker-compose -f hosting.yml up -d\n</code></pre></li> <li>Logs <pre><code>docker-compose -f hosting.yml logs -f\n</code></pre></li> </ul>              Share on X                       Share on Facebook","tags":["Networking","DNS","Proxy"]},{"location":"management/","title":"\u2757 Container Management Tools","text":"<p>Production-grade container monitoring, auto-healing and dashboard solutions.</p>","tags":["Management","Infrastructure"]},{"location":"management/#service-configuration","title":"\ud83d\udee0\ufe0f Service Configuration","text":"<ul> <li>Logging (<code>default-logging</code>)</li> <li>Labels (<code>default-labels</code>)</li> <li>Resource limits (<code>resource-limits</code>)</li> </ul>","tags":["Management","Infrastructure"]},{"location":"management/#core-services","title":"Core Services","text":"management.yml<pre><code>---\nx-logging: &amp;default-logging\n  driver: loki\n  options: &amp;default-logging-options\n    loki-url: https://loki.${SYNOLOGY_BASIC_URL}/loki/api/v1/push\n    loki-retries: 5\n    loki-batch-size: 400\n    loki-batch-wait: 2s\n    loki-timeout: 10s\n    loki-max-backoff: 5s\n    loki-min-backoff: 1s\n    loki-tenant-id: default\n\nx-labels: &amp;default-labels\n  com.centurylinklabs.watchtower.enable: true\n  recreat.container: true\n  container.label.group: management\n\nx-limits: &amp;resource-limits\n  mem_limit: 256m\n  mem_reservation: 64m\n  cpu_shares: \"512\"\n  restart: always\n  networks:\n    dockerization:\n\nservices:\n  watchtower:\n    image: containrrr/watchtower\n    container_name: watchtower\n    hostname: watchtower\n    &lt;&lt;: *resource-limits\n    logging:\n      &lt;&lt;: *default-logging\n      options:\n        &lt;&lt;: *default-logging-options\n        loki-external-labels: job=watchtower\n    environment:\n      UID: ${UID_NAS_ADMIN:-1026} # (1)!\n      GID: ${GID_NAS_ADMIN:-100} # (2)!\n      WATCHTOWER_CLEANUP: true # (3)!\n      WATCHTOWER_LABEL_ENABLE: true # (4)!\n      WATCHTOWER_DEBUG: true # (5)!\n      WATCHTOWER_ROLLING_RESTART: true # (6)!\n      WATCHTOWER_INCLUDE_STOPPED: true # (7)!\n      NO_COLOR: 1 # (8)!\n      WATCHTOWER_NO_SETUP_MESSAGE: true # (9)!\n      WATCHTOWER_TIMEOUT: 30s # (10)!\n      WATCHTOWER_NO_RESTART: false # (11)!\n      WATCHTOWER_POLL_INTERVAL: 30 # (12)!\n      WATCHTOWER_HTTP_API_UPDATE: true # (13)!\n      WATCHTOWER_HTTP_API_METRICS: true # (14)!\n      WATCHTOWER_HTTP_API_PERIODIC_POLLS: true # (15)!\n      DOCKER_TLS_VERIFY: true # (16)!\n      WATCHTOWER_LOG_LEVEL: info # (17)!\n      DOCKER_API_VERSION: 1.41 # (18)!\n      WATCHTOWER_REMOVE_VOLUMES: false # (19)!\n      WATCHTOWER_TRACE: true # (20)!\n      WATCHTOWER_HTTP_API_TOKEN: ${WATCHTOWER_HTTP_API_TOKEN:? Token is missing} # (21)!\n    ports:\n      - target: 8080\n        published: 8080\n        protocol: tcp\n        mode: host\n    volumes:\n      - type: bind\n        source: /var/run/docker.sock\n        target: /var/run/docker.sock\n        read_only: true\n      - type: bind\n        source: /etc/localtime\n        target: /etc/localtime\n        read_only: true\n      - type: bind\n        source: /root/.docker/config.json\n        target: /root/.docker/config.json\n        read_only: true\n    labels:\n      &lt;&lt;: *default-labels\n      monitoring: watchtower\n\n  autoheal:\n    image: willfarrell/autoheal\n    container_name: autoheal\n    hostname: autoheal\n    &lt;&lt;: *resource-limits\n    logging:\n      &lt;&lt;: *default-logging\n      options:\n        &lt;&lt;: *default-logging-options\n        loki-external-labels: job=autoheal\n    environment:\n      UID: ${UID_NAS_ADMIN:-1026} # (22)!\n      GID: ${GID_NAS_ADMIN:-100} # (23)!\n      AUTOHEAL_INTERVAL: 60s # (24)!\n      AUTOHEAL_CONTAINER_LABEL: recreat.container # (25)!\n      DOCKER_HOST: unix:///var/run/docker.sock # (26)!\n      WEBHOOK_URL: https://gotify.${SYNOLOGY_BASIC_URL}/message?token=${WATCHTOWER_NOTIFICATION_GOTIFY_TOKEN} # (27)!\n      AUTOHEAL_ONLY_MONITOR_RUNNING: false # (28)!\n    volumes:\n      - type: bind\n        source: /var/run/docker.sock\n        target: /var/run/docker.sock\n        read_only: true\n      - type: bind\n        source: /etc/localtime\n        target: /etc/localtime\n        read_only: true\n    labels:\n      &lt;&lt;: *default-labels\n      monitoring: autoheal\n\n  dashy:\n    container_name: dashy\n    hostname: dashy\n    image: lissy93/dashy:latest\n    &lt;&lt;: *resource-limits\n    logging:\n      &lt;&lt;: *default-logging\n      options:\n        &lt;&lt;: *default-logging-options\n        loki-external-labels: job=dashy\n    environment:\n      NODE_ENV: production # (29)!\n    ports:\n      - target: 8080\n        published: 90\n        protocol: tcp\n        mode: host\n    volumes:\n      - type: bind\n        source: ${MOUNT_PATH_DOCKER_ROOT}/compose/config/dashy.yml\n        target: /app/user-data/conf.yml\n      - type: bind\n        source: /etc/localtime\n        target: /etc/localtime\n        read_only: true\n    labels:\n      &lt;&lt;: *default-labels\n      monitoring: dashy\n\nnetworks:\n  dockerization:\n    external: true\n</code></pre> <ol> <li>User ID for permissions (default: 1026)</li> <li>Group ID for permissions (default: 100)</li> <li>Automatically clean up old images</li> <li>Enable container monitoring by label</li> <li>Enable debug mode</li> <li>Enable rolling restarts</li> <li>Monitor stopped containers</li> <li>Disable colored output</li> <li>Disable setup message</li> <li>Container stop timeout (30s)</li> <li>Disable container restarts (false)</li> <li>Check interval in seconds (30)</li> <li>Enable HTTP API updates</li> <li>Enable metrics endpoint</li> <li>Enable periodic polls via API</li> <li>Enable TLS verification</li> <li>Log level (info)</li> <li>Docker API version (1.41)</li> <li>Remove volumes with containers (false)</li> <li>Enable trace logging</li> <li>Required API token</li> <li>User ID for permissions (default: 1026)</li> <li>Group ID for permissions (default: 100)</li> <li>Health check interval (60s)</li> <li>Label to identify containers to monitor</li> <li>Docker socket path</li> <li>Gotify webhook URL for notifications</li> <li>Monitor only running containers (false)</li> <li>Environment PROD</li> </ol>","tags":["Management","Infrastructure"]},{"location":"management/#required-environment-variables","title":"\ud83d\udd10 Required Environment Variables","text":"Variable Description Required <code>UID_NAS_ADMIN</code> User ID for volume permissions \u26a0\ufe0f Recommended <code>GID_NAS_ADMIN</code> Group ID for volume permissions \u26a0\ufe0f Recommended <code>WATCHTOWER_HTTP_API_TOKEN</code> Watchtower API token \u2705 <code>MOUNT_PATH_DOCKER_ROOT</code> Base storage path \u2705 <code>SYNOLOGY_BASIC_URL</code> Base domain for services \u2705 <code>DASHY_PORT</code> Dashy web interface port \u26a0\ufe0f Recommended <p>Security Notice</p> <ul> <li>Be stored in <code>.env</code> files</li> <li>Have restricted permissions (<code>chmod 600</code>)</li> <li>Never be committed to version control</li> <li>Be rotated periodically</li> </ul>","tags":["Management","Infrastructure"]},{"location":"management/#deployment","title":"\ud83d\ude80 Deployment","text":"<ol> <li>Create <code>.env</code> file with required variables</li> <li>Initialize volumes <pre><code>mkdir -p ${MOUNT_PATH_DOCKER_ROOT}/{compose/config}\nchown -R ${UID_NAS_ADMIN:-1026}:${GID_NAS_ADMIN:-100} ${MOUNT_PATH_DOCKER_ROOT}\n</code></pre></li> <li>Start services <pre><code>docker-compose -f management.yml up -d\n</code></pre></li> </ol>","tags":["Management","Infrastructure"]},{"location":"management/#maintenance","title":"\ud83d\udd04 MaintenanceShare on Social Media","text":"<ul> <li>Updates <pre><code>docker-compose -f management.yml pull &amp;&amp; docker-compose -f management.yml up -d\n</code></pre></li> <li>Logs <pre><code>docker-compose -f management.yml logs -f\n</code></pre></li> </ul>              Share on X                       Share on Facebook","tags":["Management","Infrastructure"]},{"location":"code/","title":"\ud83d\udce6 Source Directory Overview (<code>src</code>)","text":"<p>Welcome to the technical heart of the project! This document provides a clear and concise overview of the structure and purpose of each file and folder within the <code>src</code> directory. Whether you're a new contributor or just curious, this guide will help you navigate the codebase with ease.</p>","tags":["Code"]},{"location":"code/#table-of-contents","title":"\ud83d\udcd1 Table of Contents","text":"<ul> <li>Main Entry Point</li> <li>Configuration Modules</li> <li>Utility Modules</li> <li>Type Definitions</li> </ul>","tags":["Code"]},{"location":"code/#main-entry-point","title":"\ud83d\ude80 Main Entry Point","text":"","tags":["Code"]},{"location":"code/#indexts","title":"<code>index.ts</code>","text":"<p>The main entry script for the CLI tool. It detects the operating system (macOS or Windows) and launches the appropriate CLI logic for package management (Homebrew or Chocolatey). This file contains the main menu and delegates to the relevant platform-specific functions.</p>","tags":["Code"]},{"location":"code/#configuration-modules","title":"\u2699\ufe0f Configuration Modules","text":"","tags":["Code"]},{"location":"code/#configclits","title":"<code>config/cli.ts</code>","text":"<p>Defines the <code>PackageManagerCLI</code> class, which manages the interactive main menu, package installation, updates, SSH connections, and the execution of commands from YAML files. The menu adapts to the detected platform.</p>","tags":["Code"]},{"location":"code/#configlocalstoragets","title":"<code>config/localStorage.ts</code>","text":"<p>Provides the <code>YamlDataService</code> class for loading and saving data (such as command lists) from YAML files in the <code>assets</code> directory. Relies on helpers from <code>utils/isStorage.ts</code>.</p>","tags":["Code"]},{"location":"code/#utility-modules","title":"\ud83d\udee0\ufe0f Utility Modules","text":"","tags":["Code"]},{"location":"code/#utilsyamlterminalautomatorts","title":"<code>utils/yamlTerminalAutomator.ts</code>","text":"<p>The <code>TerminalAutomator</code> class reads commands from a YAML file and executes them sequentially. Errors are logged, and execution halts on failure.</p>","tags":["Code"]},{"location":"code/#utilssectionts","title":"<code>utils/section.ts</code>","text":"<p>The <code>Section</code> class provides an interactive menu for selecting and running Docker Compose files. It supports keyboard navigation and loading environment variables from <code>.env</code> files.</p>","tags":["Code"]},{"location":"code/#utilsisstoragets","title":"<code>utils/isStorage.ts</code>","text":"<p>The <code>isStorageService</code> class offers helper methods for creating directories and file paths for YAML files in the <code>assets</code> directory.</p>","tags":["Code"]},{"location":"code/#utilsdockerts","title":"<code>utils/docker.ts</code>","text":"<p>The <code>DockerComposeUtil</code> class #encapsulates Docker Compose operations, including error handling and loading environment variables from <code>.env</code> files.</p>","tags":["Code"]},{"location":"code/#utilsbashts","title":"<code>utils/bash.ts</code>","text":"<p>The <code>BashHelper</code> class provides methods for establishing SSH connections and exiting the CLI program. It works seamlessly across Windows and Unix systems.</p>","tags":["Code"]},{"location":"code/#type-definitions","title":"\ud83d\udcdd Type Definitions","text":"","tags":["Code"]},{"location":"code/#typestypests","title":"<code>types/types.ts</code>Share on Social Media","text":"<p>Defines the <code>PackageManagerOptions</code> interface, which specifies configuration options for the CLI <code>(such as platform, commands, labels, and messages)</code>.</p>              Share on X                       Share on Facebook","tags":["Code"]},{"location":"environment/","title":"\ud83c\udf3f Environment Variables","text":"<p>These environment variables configure all Homelab services. Store sensitive values in your <code>.env</code> file and reference them in Docker Compose.</p> \ud83d\udd27 Core Configuration\ud83d\udd10 Authentication Secrets\ud83d\udce8 Email Configuration\ud83c\udf10 Networking\ud83d\udee1\ufe0f Security Variable Description Example \ud83d\udce1 <code>SYNOLOGY_BASIC_URL</code> Base URL for Synology services <code>https://synology.yourdomain.com</code> \ud83d\udcc2 <code>MOUNT_PATH_DOCKER_ROOT</code> Docker volumes root path <code>/mnt/docker</code> \ud83d\udce7 <code>EMAIL</code> Primary contact email <code>your@email.com</code> Variable Description Security \ud83d\udd11 <code>PG_PASS</code> PostgreSQL database password \ud83d\udd12 Sensitive \ud83d\udd10 <code>AUTHENTIK_SECRET_KEY</code> Autentik cryptographic key \ud83d\udd12 Sensitive \ud83d\udee0\ufe0f <code>SUDO_PASSWORD_VSCODE</code> VS Code container sudo password \ud83d\udd12 Sensitive Variable Description Required \ud83d\udce9 <code>MAIL_RECEIVER</code> Alert notifications recipient <code>alerts@yourdomain.com</code> \ud83d\udce4 <code>SMTP_PASSWORD</code> Outbound mail server password \ud83d\udd12 Yes Variable Description Service \ud83c\udf10 <code>CLOUDFLARE_TOKEN</code> Cloudflare API token \ud83d\udd12 Tunnel/DNS \ud83d\udeab <code>PI_HOLE_PASSWORD</code> Pi-hole admin interface \ud83d\udd12 DNS Variable Description Scope \ud83d\udd11 <code>INITIAL_ADMIN_PASSWORD</code> Default admin password Multiple services \ud83d\udd75\ufe0f\u200d\u2642\ufe0f <code>WATCHTOWER_HTTP_API_TOKEN</code> Container update auth \ud83d\udd12 Watchtower <p>Best Practices</p> <ul> <li>Always use <code>.env</code> files for sensitive variables</li> <li>Rotate credentials quarterly</li> <li>Restrict permissions to <code>600</code></li> <li>Never commit to version control</li> </ul> <p>Sample .env File</p> <pre><code># Core\nSYNOLOGY_BASIC_URL=synology.yourdomain.com\nMOUNT_PATH_DOCKER_ROOT=/mnt/docker\n\n# Secrets\nPG_PASS=strongpassword123\nAUTENTIK_SECRET_KEY=changeme\n</code></pre> Share on Social Media              Share on X                       Share on Facebook","tags":["Global"]},{"location":"sharedConfig/","title":"\u2699\ufe0f Shared Config","text":"<p>The following shared anchors are used across services in your docker-compose.yml file to ensure consistent configuration for logging, labeling, and resource limits.</p> LoggingLabelsResource Limits <p>Standardized Logging for Docker services</p> <p>The following shared anchors are used across services in your docker-compose.yml file to ensure consistent configuration for logging, labeling, and resource limits.</p> <pre><code>x-logging: &amp;default-logging\n  driver: \"loki\" # (1)!\n  options: &amp;default-logging-options\n    loki-url: https://loki.${SYNOLOGY_BASIC_URL}/loki/api/v1/push # (2)!\n    loki-retries: 5 # (3)!\n    loki-batch-size: 400 # (4)!\n    loki-batch-wait: 2s # (5)!\n    loki-timeout: 10s # (6)!\n    loki-max-backoff: 5s # (7)!\n    loki-min-backoff: 1s # (8)!\n    loki-tenant-id: default # (9)!\n</code></pre> <ol> <li>\u2192 Uses Grafana Loki for log aggregation</li> <li>\u2192 Dynamic URL using environment variable</li> <li>\u2192 Maximum 5 retries on failure</li> <li>\u2192 400 log lines per batch maximum</li> <li>\u2192 2 second wait for partial batches</li> <li>\u2192 10 second request timeout</li> <li>\u2192 5 seconds maximum between retries</li> <li>\u2192 1 second minimum between retries</li> <li>\u2192 Default tenant identifier</li> </ol> <p>Remember</p> <ul> <li>The <code>SYNOLOGY_BASIC_URL</code> must be set in your environment or replaced with your direct Loki URL</li> <li>These settings can be adjusted as needed, but the shown values are recommended by Loki docs for:</li> <li>Balanced performance (batch size 400)</li> <li>Reliable delivery (retries 5)</li> <li>Network resilience (timeout 10s)</li> <li>For production environments, consider:</li> <li>Increasing batch size if high log volume</li> <li>Adjusting timeouts based on network latency</li> </ul> <p>Standardized labels for Docker services</p> <p>The following shared anchors ensure consistent behavior across your <code>docker-compose.yml</code>:</p> <pre><code>x-labels: &amp;default-labels\n  com.centurylinklabs.watchtower.enable: true  # (1)!\n  recreat.container: true                      # (2)!\n  container.label.group: setup                 # (3)!\n</code></pre> <ol> <li>\u2192 Enables Watchtower to auto-update this container</li> <li>\u2192 Custom marker for deployment-triggered recreation</li> <li>\u2192 Categorizes containers (e.g., <code>proxy</code>, <code>db</code>, <code>monitoring</code>)</li> </ol> <p>Remember</p> <ul> <li>Update <code>container.label.group</code> per service</li> <li>Groups enable bulk operations via: <pre><code>docker ps --filter \"label=container.label.group=setup\"\n</code></pre></li> </ul> <p>Standardized Resource Limits for Docker services</p> <p>The following shared anchors ensure consistent behavior across your <code>docker-compose.yml</code>:</p> <pre><code>x-resource-limits: &amp;default-resource-limits\n  deploy:\n    resources:\n      limits:\n        cpus: '0.50'  # (1)!\n        memory: 512M  # (2)!\n      reservations:\n        cpus: '0.25'  # (3)!\n        memory: 256M  # (4)!\n</code></pre> <ol> <li>\u2192 Container won't exceed 50% of a CPU core</li> <li>\u2192 Hard memory cap of 512MB (OOM kill if exceeded)</li> <li>\u2192 Guaranteed 25% of a CPU core</li> <li>\u2192 Always allocated 256MB memory buffer</li> </ol> <p>Remember</p> <ul> <li>Adjust values based on your host machine capacity</li> <li>Monitor usage with <pre><code>docker stats --format \"table {{.Name}}\\t{{.CPUPerc}}\\t{{.MemUsage}}\"\n</code></pre></li> </ul>","tags":["Global"]},{"location":"sharedConfig/#example-usage","title":"Example Usage","text":"<p>Here's how to implement these shared anchors in a service definition:</p> <pre><code>version: '3.8'\n\nservices:\n  nginx:\n    image: nginx:latest\n    &lt;&lt;: *default-labels\n    &lt;&lt;: *default-resource-limits\n    logging: *default-logging\n    ports:\n      - \"80:80\"\n    environment:\n      - SYNOLOGY_BASIC_URL=yourdomain.com  # Required for Loki URL\n\n  postgres:\n    image: postgres:15\n    &lt;&lt;: *default-labels\n    &lt;&lt;: *default-resource-limits\n    logging: *default-logging\n    environment:\n      POSTGRES_PASSWORD: example\n      - SYNOLOGY_BASIC_URL=yourdomain.com\n    volumes:\n      - pgdata:/var/lib/postgresql/data\n\nx-logging: &amp;default-logging\n  driver: \"loki\"\n  options: &amp;default-logging-options\n    loki-url: https://loki.${SYNOLOGY_BASIC_URL}/loki/api/v1/push\n    loki-retries: 5\n    loki-batch-size: 400\n    loki-batch-wait: 2s\n    loki-timeout: 10s\n    loki-max-backoff: 5s\n    loki-min-backoff: 1s\n    loki-tenant-id: default\n\nx-labels: &amp;default-labels\n  com.centurylinklabs.watchtower.enable: true\n  recreat.container: true\n  container.label.group: setup\n\nx-resource-limits: &amp;default-resource-limits\n  deploy:\n    resources:\n      limits:\n        cpus: '0.50'\n        memory: 512M\n      reservations:\n        cpus: '0.25'\n        memory: 256M\n\nvolumes:\n  pgdata:\n</code></pre> Share on Social Media              Share on X                       Share on Facebook","tags":["Global"]},{"location":"brew/","title":"\ud83c\udfd7 Homebrew Installation","text":"<p>Automated installation of Homebrew on macOS and Linux. The script checks if Homebrew is already installed, installs it if necessary, and sets up the shell environment.</p>","tags":["Script","Homebrew","macOS","Linux"]},{"location":"brew/#service-configuration","title":"\ud83d\udee0\ufe0f Service Configuration","text":"<ul> <li>Detects the operating system (macOS or Linux)</li> <li>Installs Homebrew if not already present</li> <li>Updates the shell profile (<code>.zprofile</code> or <code>.profile</code>)</li> <li>Skips installation if Homebrew is already installed</li> <li>Provides user feedback in German</li> </ul> brew.sh<pre><code>#!/bin/sh\n\nOS=\"$(uname -s)\"\n\nif [ \"$OS\" = \"Darwin\" ]; then\n  if ! command -v brew &gt;/dev/null 2&gt;&amp;1; then\n    export HOMEBREW_NO_INSTALL_FROM_API=1 # (1)!\n    /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n    echo &gt;&gt; \"$HOME/.zprofile\"\n    echo 'eval \"$(/opt/homebrew/bin/brew shellenv)\"' &gt;&gt; \"$HOME/.zprofile\"\n    eval \"$(/opt/homebrew/bin/brew shellenv)\"\n  else\n    echo \"Homebrew ist bereits installiert. \u00dcberspringe Installation.\"\n    eval \"$(/opt/homebrew/bin/brew shellenv)\"\n  fi\nelif [ \"$OS\" = \"Linux\" ]; then\n  if ! command -v brew &gt;/dev/null 2&gt;&amp;1; then\n    export HOMEBREW_NO_INSTALL_FROM_API=1 # (2)!\n    /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n    echo &gt;&gt; \"$HOME/.profile\"\n    echo 'eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"' &gt;&gt; \"$HOME/.profile\"\n    eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"\n  else\n    echo \"Homebrew ist bereits installiert. \u00dcberspringe Installation.\"\n    eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"\n  fi\nelse\n  echo \"Nicht unterst\u00fctztes Betriebssystem: $OS\"\n  exit 1\nfi\n</code></pre> <ol> <li>\u2192 Prevents the use of the Homebrew API for installation and enforces the classic installation method. Recommended for compatibility and stability.</li> <li>\u2192 The script automatically adds the Homebrew environment to the appropriate profile depending on the OS: macOS: <code>.zprofile</code>, Linux: <code>.profile</code></li> </ol>","tags":["Script","Homebrew","macOS","Linux"]},{"location":"brew/#important-notes","title":"\ud83d\udd10 Important Notes","text":"<ul> <li>The script requires write permissions to the user's profile file</li> <li>Unsupported systems will abort with an error</li> <li>Homebrew should be available in the current terminal after installation</li> </ul>","tags":["Script","Homebrew","macOS","Linux"]},{"location":"brew/#usage","title":"\ud83d\ude80 Usage","text":"<pre><code>sh assets/scripts/brew.sh\n</code></pre> <ul> <li>On macOS, <code>.zprofile</code> is updated and the Homebrew environment is loaded</li> <li>On Linux, <code>.profile</code> is updated and the Homebrew environment is loaded</li> </ul>","tags":["Script","Homebrew","macOS","Linux"]},{"location":"brew/#maintenance-updates","title":"\ud83d\udd04 Maintenance &amp; Updates","text":"<ul> <li>To update Homebrew: <pre><code>brew update &amp;&amp; brew upgrade\n</code></pre></li> <li>To rerun the script, simply execute as described above</li> </ul>","tags":["Script","Homebrew","macOS","Linux"]},{"location":"brew/#references","title":"\ud83d\udd17 References","text":"<ul> <li>Homebrew Official Documentation</li> </ul> Share on Social Media              Share on X                       Share on Facebook","tags":["Script","Homebrew","macOS","Linux"]},{"location":"dotenv/","title":"\ud83d\udcc4 Dotenv","text":"dotenv.sh<pre><code>#!/bin/sh\n\nexport INFLUX_TOKEN=$(grep '^INFLUX_TOKEN=' .env | cut -d '=' -f2-)\n\n# Dashy\nexport DASHY_USERNAME=$(grep '^DASHY_USERNAME=' .env | cut -d '=' -f2-)\nexport DASHY_PASSWORD_HASH=$(grep '^DASHY_PASSWORD_HASH=' .env | cut -d '=' -f2-)\nexport WEATHER_API_KEY=$(grep '^WEATHER_API_KEY=' .env | cut -d '=' -f2-)\nexport SYNOLOGY_BASIC_URL=$(grep '^SYNOLOGY_BASIC_URL=' .env | cut -d '=' -f2-)\n</code></pre> Share on Social Media              Share on X                       Share on Facebook","tags":["Dotenv"]},{"location":"hetznerCert/","title":"\ud83d\udd10 Hetzner Certificate","text":"<p>Automates the process of issuing and deploying SSL certificates for domains managed by Hetzner DNS using acme.sh. Supports DNS-based validation and direct deployment to Synology DSM.</p>","tags":["Script","SSL","Hetzner","Certificate"]},{"location":"hetznerCert/#service-configuration","title":"\ud83d\udee0\ufe0f Service Configuration","text":"<ul> <li>Loads environment variables from <code>.env</code> file</li> <li>Installs and configures acme.sh</li> <li>Issues wildcard certificates via Hetzner DNS API</li> <li>Deploys certificates to Synology DSM</li> <li>Sets up automatic renewal</li> </ul> hetzner.sh<pre><code># Laden der Umgebungsvariablen aus der .env-Datei\nif [ -f .env ]; then # (1)!\n    export $(grep -v '^#' .env | xargs -d '\\n')\nfi\n\n# Acme.sh von GitHub herunterladen und extrahieren\nwget https://github.com/acmesh-official/acme.sh/archive/master.tar.gz # (2)!\ntar -xvzf master.tar.gz\ncd acme.sh-master\n./acme.sh --install --nocron --home /usr/local/share/acme.sh --accountemail \"$ACME_ACCOUNT_EMAIL\"\ncd ~\nsource .profile\n\n# Zertifikat ausstellen\ncd /usr/local/share/acme.sh # (3)!\nexport HETZNER_TOKEN=\"$HETZNER_TOKEN\"\n./acme.sh --issue --dns dns_hetzner -d \"$DOMAIN\" -d \"*.$DOMAIN\" --server letsencrypt\n\n# Synology Einstellungen f\u00fcr Anmeldung und Zertifikat\nexport SYNO_USERNAME=\"$SYNO_USERNAME\"\nexport SYNO_PASSWORD=\"$SYNO_PASSWORD\"\nexport SYNO_CERTIFICATE=\"\"\n\n# Zertifikat auf Synology DSM bereitstellen\n./acme.sh --deploy --home . -d \"$DOMAIN\" --deploy-hook synology_dsm # (4)!\n\n# Zertifikat ernern \n\n/usr/local/share/acme.sh/acme.sh --cron --home /usr/local/share/acme.sh/ # (5)!\n</code></pre> <ol> <li>Loads required environment variables from a <code>.env</code> file (must define <code>ACME_ACCOUNT_EMAIL</code>, <code>HETZNER_TOKEN</code>, <code>DOMAIN</code>, <code>SYNO_USERNAME</code>, <code>SYNO_PASSWORD</code>).</li> <li>Installs acme.sh if it is not already available on the system.</li> <li>Issues a wildcard SSL certificate for the specified domain using Hetzner DNS API.</li> <li>Deploys the issued certificate directly to Synology DSM using the acme.sh deploy hook.</li> <li>Optional: Adds a cron job to automatically renew certificates</li> </ol>","tags":["Script","SSL","Hetzner","Certificate"]},{"location":"hetznerCert/#important-notes","title":"\ud83d\udd10 Important Notes","text":"<ul> <li>Requires internet access and permissions to install software</li> <li>Synology DSM must support certificate deployment via acme.sh</li> <li>The script will attempt to renew certificates automatically if cron is enabled</li> <li>The <code>.env</code> file must be present and contain all required variables</li> </ul>","tags":["Script","SSL","Hetzner","Certificate"]},{"location":"hetznerCert/#usage","title":"\ud83d\ude80 Usage","text":"<pre><code>sh assets/scripts/hetzner_cert.sh\n</code></pre> <ul> <li>Ensure your <code>.env</code> file contains: <code>ACME_ACCOUNT_EMAIL</code>, <code>HETZNER_TOKEN</code>, <code>DOMAIN</code>, <code>SYNO_USERNAME</code>, <code>SYNO_PASSWORD</code></li> </ul>","tags":["Script","SSL","Hetzner","Certificate"]},{"location":"hetznerCert/#maintenance-updates","title":"\ud83d\udd04 Maintenance &amp; Updates","text":"<ul> <li>To manually renew certificates: <pre><code>acme.sh --renew -d yourdomain.com --force\n</code></pre></li> <li>To update acme.sh: <pre><code>acme.sh --upgrade\n</code></pre></li> </ul>","tags":["Script","SSL","Hetzner","Certificate"]},{"location":"hetznerCert/#references","title":"\ud83d\udd17 References","text":"<ul> <li>acme.sh Documentation</li> <li>Hetzner DNS API </li> </ul> Share on Social Media              Share on X                       Share on Facebook","tags":["Script","SSL","Hetzner","Certificate"]},{"location":"macvlan/","title":"\ud83c\udf10 Docker Macvlan","text":"<p>This script interactively creates a Docker macvlan network, supporting both IPv4 and IPv6 configurations. It prompts the user for network details and executes the appropriate <code>docker network create</code> command.</p>","tags":["Script","Docker","Networking"]},{"location":"macvlan/#service-configuration","title":"\ud83d\udee0\ufe0f Service Configuration","text":"<ul> <li>Interactive prompts for network name and IPv4 prefix</li> <li>Automatically constructs IPv4 subnet and gateway</li> <li>Supports both IPv4-only and dual-stack (IPv4 + IPv6) networks</li> <li>Uses <code>eth0</code> as the default parent interface and bridge mode</li> </ul>","tags":["Script","Docker","Networking"]},{"location":"macvlan/#process","title":"Process","text":"macvlan.sh<pre><code>#!/bin/bash\n\nread -p \"Enter the Docker network name: \" NETWORK_NAME # (1)!\nread -p \"Enter the first three parts of the IPv4 address (e.g. 10.100.0): \" IP_PREFIX # (2)!\n\nSUBNET_IPV4=\"${IP_PREFIX}.0/24\" # (3)!\nGATEWAY_IPV4=\"${IP_PREFIX}.254\" # (4)!\n\necho \"Select network type:\"\necho \"1) IPv4 and IPv6\"\necho \"2) IPv4 only\"\nread -p \"Selection (1 or 2): \" NET_TYPE # (5)!\n\nif [ \"$NET_TYPE\" = \"1\" ]; then\n    IPV6_PREFIX=\"fd00::\" # (6)!\n    SUBNET_IPV6=\"${IPV6_PREFIX}/64\" # (7)!\n    docker network create -d macvlan \\\n      --subnet=$SUBNET_IPV4 \\\n      --gateway=$GATEWAY_IPV4 \\\n      --subnet=$SUBNET_IPV6 \\\n      --ipv6 \\\n      -o parent=eth0 \\\n      -o macvlan_mode=bridge \\\n      $NETWORK_NAME # (8)\nelif [ \"$NET_TYPE\" = \"2\" ]; then\n    docker network create -d macvlan \\\n      --subnet=$SUBNET_IPV4 \\\n      --gateway=$GATEWAY_IPV4 \\\n      -o parent=eth0 \\\n      -o macvlan_mode=bridge \\\n      $NETWORK_NAME # (9)\nelse\n    echo \"Invalid selection. Please restart the script.\"\n    exit 1\nfi\n</code></pre> <ol> <li>Prompts for the Docker network name.</li> <li>Prompts for the first three octets of the IPv4 address (e.g. 10.100.0).</li> <li>Constructs the IPv4 subnet in CIDR notation (e.g. 10.100.0.0/24).</li> <li>Sets the IPv4 gateway to the .254 address in the subnet.</li> <li>Prompts for network type: dual-stack (IPv4+IPv6) or IPv4 only.</li> <li>Uses a generic IPv6 prefix for dual-stack networks.</li> <li>Constructs the IPv6 subnet in CIDR notation.</li> <li>Creates a dual-stack macvlan network with both IPv4 and IPv6.</li> <li>Creates an IPv4-only macvlan network.</li> </ol>","tags":["Script","Docker","Networking"]},{"location":"macvlan/#important-notes","title":"\ud83d\udd10 Important Notes","text":"<ul> <li>Requires Docker to be installed and running</li> <li>Must be run with sufficient privileges to create Docker networks</li> <li>Only <code>eth0</code> is supported as the parent interface (edit the script to change)</li> <li>The script uses bridge mode for macvlan</li> </ul>","tags":["Script","Docker","Networking"]},{"location":"macvlan/#usage","title":"\ud83d\ude80 Usage","text":"<pre><code>sh assets/scripts/macvlan.sh\n</code></pre> <ul> <li>Run the script and follow the interactive prompts</li> </ul>","tags":["Script","Docker","Networking"]},{"location":"macvlan/#maintenance-updates","title":"\ud83d\udd04 Maintenance &amp; Updates","text":"<ul> <li>To list macvlan networks: <pre><code>docker network ls | grep macvlan\n</code></pre></li> <li>To remove a macvlan network: <pre><code>docker network rm &lt;network_name&gt;\n</code></pre></li> </ul>","tags":["Script","Docker","Networking"]},{"location":"macvlan/#references","title":"\ud83d\udd17 References","text":"<ul> <li>Docker Macvlan Networks </li> </ul> Share on Social Media              Share on X                       Share on Facebook","tags":["Script","Docker","Networking"]},{"location":"nas/","title":"\ud83d\uddc4\ufe0f NAS Script","text":"<p>This script automates the installation of Entware and basic tools (like <code>nano</code>) on Synology NAS systems. It checks prerequisites, prepares directories, mounts required paths, installs Entware, and configures the environment for immediate use.</p>","tags":["Script","Synology","NAS","Entware"]},{"location":"nas/#service-configuration","title":"\ud83d\udee0\ufe0f Service Configuration","text":"<ul> <li>Checks if the script is running on a Synology NAS (verifies presence of <code>/volume1</code>)</li> <li>Creates and mounts the Entware directory (<code>/volume1/@Entware/opt</code> \u2192 <code>/opt</code>)</li> <li>Installs Entware if not present</li> <li>Adds Entware PATH to <code>~/.profile</code> if not configured</li> <li>Updates Entware package list and installs basic tools (<code>nano</code>)</li> <li>Provides color-coded, timestamped log output</li> </ul> nas.sh<pre><code>#!/bin/bash\n\n# =============================================================================\n# Synology NAS Setup Script\n# Installiert Entware und grundlegende Tools\n# =============================================================================\n\nset -e  # Beende bei Fehlern\n\n# Farben f\u00fcr Ausgabe\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\n# Logging-Funktion\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[ERROR] $1${NC}\" &gt;&amp;2\n}\n\nwarning() {\n    echo -e \"${YELLOW}[WARNING] $1${NC}\"\n}\n\n# =============================================================================\n# 1. Voraussetzungen pr\u00fcfen\n# =============================================================================\nlog \"Pr\u00fcfe Voraussetzungen...\" # (1)!\n\n# Pr\u00fcfe ob wir auf einem Synology NAS sind\nif [ ! -d \"/volume1\" ]; then\n    error \"Dieses Skript ist nur f\u00fcr Synology NAS-Systeme gedacht!\"\n    exit 1\nfi\n\n# Pr\u00fcfe Container Manager Verzeichnis\nif [ ! -d \"/volume1/@appconf/ContainerManager\" ]; then\n    warning \"Container Manager Verzeichnis nicht gefunden\"\nfi\n\n# =============================================================================\n# 2. Entware Verzeichnis vorbereiten\n# =============================================================================\nlog \"Bereite Entware Verzeichnis vor...\" # (2)!\n\nENTWARE_DIR=\"/volume1/@Entware\"\nOPT_DIR=\"$ENTWARE_DIR/opt\"\n\n# Erstelle Verzeichnisse\nif [ ! -d \"$ENTWARE_DIR\" ]; then\n    log \"Erstelle Entware Hauptverzeichnis...\"\n    mkdir -p \"$ENTWARE_DIR\"\nfi\n\nif [ ! -d \"$OPT_DIR\" ]; then\n    log \"Erstelle opt Verzeichnis...\"\n    mkdir -p \"$OPT_DIR\"\nfi\n\n# =============================================================================\n# 3. Mount-Point einrichten\n# =============================================================================\nlog \"Richte Mount-Point ein...\" # (3)!\n\n# Pr\u00fcfe ob bereits gemountet\nif ! mountpoint -q /opt; then\n    log \"Mounte Entware opt Verzeichnis...\"\n    mount -o bind \"$OPT_DIR\" /opt\nelse\n    warning \"/opt ist bereits gemountet\"\nfi\n\n# Symlink erstellen (falls nicht vorhanden)\nif [ ! -L \"/opt\" ]; then\n    log \"Erstelle Symlink...\"\n    ln -sf \"$OPT_DIR\" /opt\nfi\n\n# =============================================================================\n# 4. Entware installieren\n# =============================================================================\nlog \"Installiere Entware...\" # (4)!\n\n# Pr\u00fcfe ob Entware bereits installiert ist\nif [ ! -f \"/opt/bin/opkg\" ]; then\n    log \"Lade Entware Installer herunter...\"\n    wget -O - https://bin.entware.net/x64-k3.2/installer/generic.sh | /bin/sh\nelse\n    warning \"Entware scheint bereits installiert zu sein\"\nfi\n\n# =============================================================================\n# 5. System-Informationen anzeigen\n# =============================================================================\nlog \"System-Informationen:\" # (5)!\necho \"Architektur: $(uname -m)\"\necho \"CPU-Info:\"\ncat /proc/cpuinfo | grep \"model name\" | head -1\n\n# =============================================================================\n# 6. PATH konfigurieren\n# =============================================================================\nlog \"Konfiguriere PATH...\" # (6)!\n\n# Pr\u00fcfe ob PATH bereits konfiguriert ist\nif ! grep -q \"/opt/bin:/opt/sbin\" ~/.profile; then\n    log \"F\u00fcge Entware PATH zu .profile hinzu...\"\n    echo 'export PATH=/opt/bin:/opt/sbin:$PATH' &gt;&gt; ~/.profile\nelse\n    warning \"PATH bereits in .profile konfiguriert\"\nfi\n\n# PATH f\u00fcr aktuelle Session setzen\nexport PATH=/opt/bin:/opt/sbin:$PATH\n\n# =============================================================================\n# 7. Entware aktualisieren und Tools installieren\n# =============================================================================\nlog \"Aktualisiere Entware Paketliste...\" # (7)!\nopkg update\n\nlog \"Installiere nano...\"\nopkg install nano\n\n# =============================================================================\n# 8. Abschluss\n# =============================================================================\nlog \"Installation abgeschlossen!\"\nlog \"F\u00fchre 'source ~/.profile' aus oder starte eine neue Shell-Session\"\nlog \"Verf\u00fcgbare Befehle: opkg, nano\"\n\n# Teste Installation\nif command -v opkg &gt;/dev/null 2&gt;&amp;1; then\n    log \"Entware erfolgreich installiert \u2713\"\nelse\n    error \"Entware Installation fehlgeschlagen!\"\n    exit 1\nfi\n</code></pre> <ol> <li>Verifies the script is running on a Synology NAS</li> <li>Creates the Entware directory structure</li> <li>Binds the opt directory to /opt and creates symlink if needed</li> <li>Installs Entware if not present</li> <li>Adds Entware PATH to ~/.profile and sets it for current session</li> <li>Updates package list and installs nano</li> <li>Verifies successful installation</li> </ol>","tags":["Script","Synology","NAS","Entware"]},{"location":"nas/#important-notes","title":"\ud83d\udd10 Important Notes","text":"<ul> <li>Only for Synology NAS systems (checks for /volume1)</li> <li>Must be executed with sufficient privileges</li> <li>Only adds PATH if not already configured</li> <li>After installation, start a new shell session or run source ~/.profile</li> </ul>","tags":["Script","Synology","NAS","Entware"]},{"location":"nas/#usage","title":"\ud83d\ude80 Usage","text":"<pre><code>sh assets/scripts/nas.sh\n</code></pre>","tags":["Script","Synology","NAS","Entware"]},{"location":"nas/#references","title":"\ud83d\udd17 References","text":"<ul> <li>Entware Offizielle Dokumentation </li> </ul> Share on Social Media              Share on X                       Share on Facebook","tags":["Script","Synology","NAS","Entware"]},{"location":"powerlevel10k/","title":"\ud83c\udfa8 Powerlevel10k Script","text":"<p>This script adds the Powerlevel10k theme to your <code>.zshrc</code> if it is not already present, and reloads your Zsh configuration. It is intended for macOS systems using Homebrew.</p>","tags":["Script","Zsh","Theme","Powerlevel10k"]},{"location":"powerlevel10k/#features","title":"\ud83d\udee0\ufe0f Features","text":"<ul> <li>Checks if Powerlevel10k is already sourced in <code>.zshrc</code></li> <li>Appends the theme source line if missing</li> <li>Reloads <code>.zshrc</code> to apply changes immediately</li> <li>Provides user feedback in German</li> </ul> powerlevel10k.sh<pre><code>#!/usr/bin/env zsh\n\nif ! grep -Fxq \"source /opt/homebrew/share/powerlevel10k/powerlevel10k.zsh-theme\" ~/.zshrc; then\n  echo 'source /opt/homebrew/share/powerlevel10k/powerlevel10k.zsh-theme' &gt;&gt; ~/.zshrc\n  echo \"Powerlevel10k wurde zur .zshrc hinzugef\u00fcgt.\" # (1)!\n  source ~/.zshrc\nelse\n  echo \"Powerlevel10k ist bereits in der .zshrc eingetragen.\"\nfi\n</code></pre> <ol> <li>\u2192 Starts the script with Zsh (ensures Zsh is used).</li> </ol>","tags":["Script","Zsh","Theme","Powerlevel10k"]},{"location":"powerlevel10k/#usage","title":"\ud83d\ude80 Usage","text":"<pre><code>zsh assets/scripts/powerLevel10.sh\n</code></pre> <ul> <li>Run in a Zsh shell on macOS with Powerlevel10k installed via Homebrew</li> </ul>","tags":["Script","Zsh","Theme","Powerlevel10k"]},{"location":"powerlevel10k/#notes","title":"\u26a0\ufe0f Notes","text":"<ul> <li>Only modifies <code>.zshrc</code> if the theme is not already present</li> <li>Assumes Powerlevel10k is installed at <code>/opt/homebrew/share/powerlevel10k/powerlevel10k.zsh-theme</code></li> </ul>","tags":["Script","Zsh","Theme","Powerlevel10k"]},{"location":"powerlevel10k/#references","title":"\ud83d\udd17 References","text":"<ul> <li>Powerlevel10k Theme </li> </ul> Share on Social Media              Share on X                       Share on Facebook","tags":["Script","Zsh","Theme","Powerlevel10k"]},{"location":"venv/","title":"\ud83d\udc0d Venv Script","text":"<p>This script automates the creation of a Python virtual environment, installs dependencies from <code>requirements.txt</code>, and builds the MkDocs documentation site. It is intended for use on Windows systems (using <code>venv/Scripts/activate</code>).</p>","tags":["Script","Python","MkDocs","Virtualenv"]},{"location":"venv/#features","title":"\ud83d\udcd1 Features","text":"<ul> <li>Creates a Python virtual environment in the <code>venv</code> directory</li> <li>Installs dependencies from <code>requirements.txt</code></li> <li>Builds the MkDocs documentation site with verbose output</li> <li>Installs MkDocs if not already present</li> </ul> venv.sh<pre><code>#!/bin/bash\n\npython3 -m venv venv # (1)!\nsource venv/Scripts/activate # (2)!\npip install -r config/requirements.txt # (3)!\nmkdocs build --verbose # (4)!\n</code></pre> <ol> <li>\u2192 Creates Python virtual environment in <code>venv</code> folder</li> <li>\u2192 Activates the environment using Windows path</li> <li>\u2192 Installs all dependencies from requirements file</li> <li>\u2192 Builds MkDocs documentation with detailed output</li> </ol>","tags":["Script","Python","MkDocs","Virtualenv"]},{"location":"venv/#usage","title":"\ud83d\ude80 Usage","text":"<pre><code>sh assets/scripts/venv.sh\n</code></pre> <ul> <li>Run in the project root directory</li> <li>Make sure <code>python3</code> and <code>pip</code> are installed</li> </ul>","tags":["Script","Python","MkDocs","Virtualenv"]},{"location":"venv/#notes","title":"\u26a0\ufe0f Notes","text":"<ul> <li>The script uses Windows-style activation (<code>venv/Scripts/activate</code>)</li> <li>Adjust the activation path for Unix systems if needed</li> </ul>","tags":["Script","Python","MkDocs","Virtualenv"]},{"location":"venv/#references","title":"\ud83d\udd17 References","text":"<ul> <li>Python venv Documentation</li> <li>MkDocs Documentation </li> </ul> Share on Social Media              Share on X                       Share on Facebook","tags":["Script","Python","MkDocs","Virtualenv"]},{"location":"archive/2025/","title":"2025","text":""},{"location":"page/2/","title":"\ud83c\udfe0 Home","text":""},{"location":"page/3/","title":"\ud83c\udfe0 Home","text":""},{"location":"page/4/","title":"\ud83c\udfe0 Home","text":""},{"location":"page/5/","title":"\ud83c\udfe0 Home","text":""},{"location":"archive/2025/page/2/","title":"2025","text":""},{"location":"archive/2025/page/3/","title":"2025","text":""},{"location":"archive/2025/page/4/","title":"2025","text":""},{"location":"archive/2025/page/5/","title":"2025","text":""}]}